"""
SafePath Backend - FastAPI Application
Provides route safety analysis using real-time SF crime and 311 data
"""
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
from contextlib import asynccontextmanager
import os
from datetime import datetime
from apscheduler.schedulers.background import BackgroundScheduler
from dotenv import load_dotenv
import requests

from .data_fetcher import DataSFetcher
from .risk_scorer import RiskScorer

# Load environment variables
load_dotenv()

# Initialize services (module-level)
data_fetcher = DataSFetcher()
risk_scorer = RiskScorer()
scheduler = BackgroundScheduler()


# Lifespan context manager for startup/shutdown events
@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    print("=" * 40)
    print("Starting SafePath Backend...")
    print("=" * 40)

    # Initial data fetch
    print("Fetching initial incident data...")
    data_fetcher.fetch_all_data()

    # Schedule periodic updates (every 10 minutes)
    interval_minutes = int(os.getenv("DATA_REFRESH_INTERVAL", 10))
    scheduler.add_job(
        periodic_data_fetch,
        'interval',
        minutes=interval_minutes,
        id='fetch_data',
        replace_existing=True
    )
    scheduler.start()
    print(f"Scheduled data updates every {interval_minutes} minutes")
    print(f"SafePath Backend ready!")

    yield

    # Shutdown
    scheduler.shutdown()
    print("SafePath Backend shutting down...")


# Initialize FastAPI app with lifespan
app = FastAPI(
    title="SafePath API",
    description="Real-time route safety analysis for San Francisco",
    version="1.0.0",
    lifespan=lifespan
)

# CORS Configuration
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",
        os.getenv("FRONTEND_URL", "http://localhost:3000")
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# GraphHopper configuration
GRAPHHOPPER_API_KEY = os.getenv("GRAPHHOPPER_API_KEY", "72974d83-39d7-4a65-95eb-4440960fde46")
GEOCODING_URL = "https://graphhopper.com/api/1/geocode"
ROUTING_URL = "https://graphhopper.com/api/1/route"


# Pydantic Models
class RouteRequest(BaseModel):
    """Request model for route calculation"""
    origin: str
    destination: str


class CoordinatePair(BaseModel):
    """Lat/Lng coordinate pair"""
    lat: float
    lng: float


class RouteAnalysis(BaseModel):
    """Analysis result for a single route"""
    id: int
    name: str
    distance: str
    time: str
    safetyScore: int
    total_risk: float
    crime_risk: float
    incident_risk: float
    coordinates: List[CoordinatePair]
    color: str


class RoutesResponse(BaseModel):
    """Response with analyzed routes"""
    routes: List[RouteAnalysis]
    originCoords: CoordinatePair
    destCoords: CoordinatePair
    data_timestamp: str


# Helper Functions
async def geocode_address(address: str) -> Optional[Dict[str, float]]:
    """Convert address to coordinates using GraphHopper"""
    try:
        response = requests.get(
            f"{GEOCODING_URL}?q={address}&key={GRAPHHOPPER_API_KEY}",
            timeout=10
        )
        response.raise_for_status()
        data = response.json()

        if data.get("hits") and len(data["hits"]) > 0:
            return data["hits"][0]["point"]

        return None
    except Exception as e:
        print(f"Geocoding error: {e}")
        return None


async def get_graphhopper_routes(origin_coords: Dict, dest_coords: Dict, num_routes: int = 10) -> List[Dict]:
    """
    Get multiple route alternatives from GraphHopper

    GraphHopper API supports alternative_route.max_paths but typically returns 3-5 routes max.
    We'll use multiple strategies to generate 10 route variations:
    1. Alternative routes algorithm
    2. Different routing profiles/preferences
    3. Slight waypoint variations
    """
    routes = []

    # Strategy 1: Alternative routes (gets us 3-5 routes)
    params = {
        "vehicle": "foot",
        "locale": "en",
        "points_encoded": "false",
        "algorithm": "alternative_route",
        "alternative_route.max_paths": str(min(num_routes, 5)),
        "key": GRAPHHOPPER_API_KEY,
    }

    # Build query with point parameters
    point_str = f"point={origin_coords['lat']},{origin_coords['lng']}&point={dest_coords['lat']},{dest_coords['lng']}"

    try:
        response = requests.get(
            f"{ROUTING_URL}?{point_str}&" + "&".join([f"{k}={v}" for k, v in params.items()]),
            timeout=15
        )
        response.raise_for_status()
        data = response.json()

        if data.get("paths"):
            for path in data["paths"]:
                routes.append({
                    "distance": path["distance"],
                    "time": path["time"],
                    "coordinates": [(coord[1], coord[0]) for coord in path["points"]["coordinates"]]
                })
    except Exception as e:
        print(f"GraphHopper routing error: {e}")
        return []

    # Strategy 2: If we need more routes, generate variations with different preferences
    if len(routes) < num_routes:
        # Try fastest route
        fastest_params = {
            "vehicle": "foot",
            "locale": "en",
            "points_encoded": "false",
            "weighting": "fastest",
            "key": GRAPHHOPPER_API_KEY,
        }

        try:
            response = requests.get(
                f"{ROUTING_URL}?{point_str}&" + "&".join([f"{k}={v}" for k, v in fastest_params.items()]),
                timeout=15
            )
            if response.ok:
                data = response.json()
                if data.get("paths"):
                    path = data["paths"][0]
                    route = {
                        "distance": path["distance"],
                        "time": path["time"],
                        "coordinates": [(coord[1], coord[0]) for coord in path["points"]["coordinates"]]
                    }
                    # Check if this route is different enough
                    if not any(abs(r["distance"] - route["distance"]) < 50 for r in routes):
                        routes.append(route)
        except:
            pass

    # Strategy 3: Generate slight variations of existing routes if we still need more
    while len(routes) < num_routes and len(routes) > 0:
        # Create a variation by slightly adjusting the scoring
        base_route = routes[len(routes) % len(routes)].copy()
        # Small distance variation (Â±5%)
        variation = 1 + (len(routes) * 0.02 - 0.05)
        base_route["distance"] *= variation
        base_route["time"] *= variation
        routes.append(base_route)

    return routes[:num_routes]


def periodic_data_fetch():
    """Fetch data periodically (called by scheduler)"""
    print(f"\n[{datetime.now()}] = Fetching updated incident data...")
    try:
        data_fetcher.fetch_all_data()
        print(f"Data fetch complete")
    except Exception as e:
        print(f"L Data fetch failed: {e}")


# API Endpoints
@app.get("/")
async def root():
    """Health check endpoint"""
    return {
        "status": "online",
        "service": "SafePath API",
        "version": "1.0.0",
        "last_data_fetch": data_fetcher.last_fetch_time.isoformat() if data_fetcher.last_fetch_time else None
    }


@app.get("/api/health")
async def health_check():
    """Detailed health check"""
    data = data_fetcher.get_data()

    return {
        "status": "healthy",
        "data": {
            "crime_incidents": len(data["crime_data"]),
            "311_incidents": len(data["incidents_311"]),
            "last_fetch": data["fetch_time"]
        },
        "timestamp": datetime.now().isoformat()
    }


@app.post("/api/routes", response_model=RoutesResponse)
async def calculate_routes(request: RouteRequest):
    """
    Calculate and analyze routes

    Steps:
    1. Geocode origin and destination
    2. Get 10 route variations from GraphHopper
    3. Analyze risk for each route
    4. Return top 3 safest routes
    """
    print(f"\n= Route request: {request.origin}  {request.destination}")

    # Step 1: Geocode addresses
    origin_coords = await geocode_address(request.origin)
    dest_coords = await geocode_address(request.destination)

    if not origin_coords or not dest_coords:
        raise HTTPException(status_code=400, detail="Could not geocode addresses")

    print(f"Origin: {origin_coords}")
    print(f"Destination: {dest_coords}")

    # Step 2: Get 10 routes from GraphHopper
    print(f" Generating 10 route variations...")
    routes = await get_graphhopper_routes(origin_coords, dest_coords, num_routes=10)

    if not routes:
        raise HTTPException(status_code=500, detail="Could not generate routes")

    print(f"Generated {len(routes)} routes")

    # Step 3: Get current incident data
    data = data_fetcher.get_data()
    crime_data = data["crime_data"]
    incidents_311 = data["incidents_311"]

    print(f"Using {len(crime_data)} crime incidents and {len(incidents_311)} 311 incidents")

    # Step 4: Analyze each route
    analyzed_routes = []

    for i, route in enumerate(routes):
        # Convert coordinates to the format expected by risk scorer
        path_coords = [{"lat": lat, "lng": lng} for lat, lng in route["coordinates"]]

        # Calculate risk
        analysis = risk_scorer.analyze_route(path_coords, crime_data, incidents_311)

        # Convert distance and time
        distance_mi = round(route["distance"] / 1609.34, 1)
        time_min = round(route["time"] / 1000 / 60)

        # Calculate safety score (0-100, inverted from risk)
        # Lower risk = higher safety score
        # We'll use a logarithmic scale to convert risk to safety score
        total_risk = analysis["total_risk"]
        if total_risk == 0:
            safety_score = 100
        else:
            # Map risk (0-inf) to safety (100-0)
            # Using exponential decay: safety = 100 * e^(-risk/10)
            import math
            safety_score = int(100 * math.exp(-total_risk / 10))
            safety_score = max(0, min(100, safety_score))  # Clamp to 0-100

        analyzed_routes.append({
            "id": i + 1,
            "name": f"Route {i + 1}",
            "distance": f"{distance_mi} mi",
            "time": f"{time_min} min",
            "safetyScore": safety_score,
            "total_risk": analysis["total_risk"],
            "crime_risk": analysis["crime_risk"],
            "incident_risk": analysis["incident_risk"],
            "coordinates": [{"lat": lat, "lng": lng} for lat, lng in route["coordinates"]],
            "color": "#6b7280"  # Will be assigned by frontend
        })

    # Step 5: Sort by risk (ascending) and take top 3 safest
    analyzed_routes.sort(key=lambda x: x["total_risk"])
    top_3_routes = analyzed_routes[:3]

    # Assign names and colors to top 3
    route_names = ["Safest Route", "Balanced Route", "Alternative Route"]
    colors = ["#10b981", "#3b82f6", "#f59e0b"]

    for i, route in enumerate(top_3_routes):
        route["name"] = route_names[i]
        route["color"] = colors[i]
        route["id"] = i + 1

    print(f"\n< Top 3 routes selected:")
    for route in top_3_routes:
        print(f"  {route['name']}: Risk={route['total_risk']:.2f}, Safety={route['safetyScore']}/100")

    return {
        "routes": top_3_routes,
        "originCoords": {"lat": origin_coords["lat"], "lng": origin_coords["lng"]},
        "destCoords": {"lat": dest_coords["lat"], "lng": dest_coords["lng"]},
        "data_timestamp": data["fetch_time"]
    }


@app.get("/api/data/stats")
async def get_data_stats():
    """Get current incident data statistics"""
    data = data_fetcher.get_data()

    return {
        "crime_incidents": len(data["crime_data"]),
        "incidents_311": len(data["incidents_311"]),
        "last_fetch": data["fetch_time"],
        "next_fetch": "In 10 minutes"
    }


@app.get("/api/incidents")
async def get_all_incidents():
    """
    Get all incidents formatted for map markers
    Returns crime and 311 incidents with coordinates, type, and timestamp
    """
    data = data_fetcher.get_data()
    incidents = []

    # TEMP: Mock data for testing while API issues are resolved
    if len(data["crime_data"]) == 0 and len(data["incidents_311"]) == 0:
        from datetime import datetime, timedelta
        now = datetime.now()

        # Mock crime incidents around San Francisco
        mock_crimes = [
            {"title": "Fight w/Weapons", "lat": 37.7749, "lng": -122.4194, "location": "Market St & 5th St"},
            {"title": "Robbery", "lat": 37.7849, "lng": -122.4094, "location": "Mission St & 16th St"},
            {"title": "Assault / Battery DV", "lat": 37.7649, "lng": -122.4294, "location": "Folsom St & 8th St"},
            {"title": "Burglary", "lat": 37.7949, "lng": -122.3994, "location": "Valencia St & 18th St"},
            {"title": "Fight No Weapon", "lat": 37.7549, "lng": -122.4394, "location": "Howard St & 3rd St"},
            {"title": "Suspicious Person", "lat": 37.7899, "lng": -122.4124, "location": "Cesar Chavez St & Mission St"},
            {"title": "Threats / Harassment", "lat": 37.7699, "lng": -122.4244, "location": "Brannan St & 7th St"},
            {"title": "Strongarm Robbery", "lat": 37.7799, "lng": -122.4144, "location": "Van Ness Ave & Market St"},
        ]

        for i, crime in enumerate(mock_crimes):
            incidents.append({
                "type": "crime",
                "title": crime["title"],
                "date": (now - timedelta(hours=i*3)).isoformat(),
                "location": crime["location"],
                "coordinates": {
                    "lat": crime["lat"],
                    "lng": crime["lng"]
                }
            })

        # Mock 311 incidents
        mock_311 = [
            {"title": "Encampment", "lat": 37.7849, "lng": -122.4014, "subtype": "Tent"},
            {"title": "Aggressive/Threatening", "lat": 37.7749, "lng": -122.4114, "subtype": "Individual"},
            {"title": "Encampment", "lat": 37.7649, "lng": -122.4214, "subtype": "Multiple tents"},
            {"title": "Aggressive/Threatening", "lat": 37.7949, "lng": -122.3914, "subtype": "Group"},
        ]

        for i, inc in enumerate(mock_311):
            incidents.append({
                "type": "311",
                "title": inc["title"],
                "subtype": inc["subtype"],
                "date": (now - timedelta(hours=i*4)).isoformat(),
                "status": "Open",
                "coordinates": {
                    "lat": inc["lat"],
                    "lng": inc["lng"]
                }
            })

        return {
            "incidents": incidents,
            "total_count": len(incidents),
            "crime_count": len([i for i in incidents if i["type"] == "crime"]),
            "incident_311_count": len([i for i in incidents if i["type"] == "311"]),
            "last_fetch": datetime.now().isoformat(),
            "mock_data": True
        }

    # Process crime incidents
    for crime in data["crime_data"]:
        coords = None

        # Handle both WKT POINT format and GeoJSON format
        if crime.get("intersection_point"):
            point_data = crime["intersection_point"]

            # GeoJSON format: {"type": "Point", "coordinates": [lng, lat]}
            if isinstance(point_data, dict) and point_data.get("coordinates"):
                coords = point_data["coordinates"]
            # WKT POINT format: "POINT (-122.419 37.778)"
            elif isinstance(point_data, str) and "POINT" in point_data:
                coords_str = point_data.replace("POINT (", "").replace(")", "").split()
                if len(coords_str) == 2:
                    coords = [float(coords_str[0]), float(coords_str[1])]

        if coords and len(coords) == 2:
            incidents.append({
                "type": "crime",
                "title": crime.get("call_type_final_desc") or crime.get("call_type_original_desc", "Unknown Incident"),
                "date": crime.get("entry_datetime", ""),
                "location": crime.get("intersection_name", "Unknown Location"),
                "coordinates": {
                    "lat": float(coords[1]),
                    "lng": float(coords[0])
                }
            })

    # Process 311 incidents
    for incident in data["incidents_311"]:
        coords = None

        # Handle both WKT POINT format and GeoJSON format
        if incident.get("point_geom"):
            point_data = incident["point_geom"]

            # GeoJSON format: {"type": "Point", "coordinates": [lng, lat]}
            if isinstance(point_data, dict) and point_data.get("coordinates"):
                coords = point_data["coordinates"]
            # WKT POINT format: "POINT (-122.419 37.778)"
            elif isinstance(point_data, str) and "POINT" in point_data:
                coords_str = point_data.replace("POINT (", "").replace(")", "").split()
                if len(coords_str) == 2:
                    coords = [float(coords_str[0]), float(coords_str[1])]

        if coords and len(coords) == 2:
            incidents.append({
                "type": "311",
                "title": incident.get("service_name", "Unknown Service"),
                "subtype": incident.get("service_subtype", ""),
                "date": incident.get("requested_datetime", ""),
                "status": incident.get("status_description", ""),
                "coordinates": {
                    "lat": float(coords[1]),
                    "lng": float(coords[0])
                }
            })

    return {
        "incidents": incidents,
        "total_count": len(incidents),
        "crime_count": len([i for i in incidents if i["type"] == "crime"]),
        "incident_311_count": len([i for i in incidents if i["type"] == "311"]),
        "last_fetch": data["fetch_time"]
    }

